# LlamaCloud API Configuration
LLAMA_CLOUD_API_KEY=your_api_key_here

# Optional Configuration
# LLAMA_CLOUD_BASE_URL=https://api.cloud.llamaindex.ai  # Only needed if using a different region (e.g., EU)

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Ollama Configuration (for local Llama models)
# No API key needed - Ollama runs locally
# Default URL: http://localhost:11434

# Optional: LlamaTrace Phoenix Observability (https://llamatrace.com)
PHOENIX_API_KEY=your_phoenix_api_key_here 